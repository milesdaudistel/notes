{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tier 1———————————————————————————\n",
    "\n",
    "`What do you want to do?`\n",
    "You want a language that goes as fast as possible.\n",
    "How are you going to achieve that?\n",
    "The cloud allows anyone (with money) to easily access parallel computers.\n",
    "This means that all programs, compilers included, can be much more powerful.\n",
    "Things like stoke and klee can take advantage of this.\n",
    "Furthermore, stoke can take advantage of different hardware architectures.\n",
    "The cloud offers a lot of powerful architecture that you could not get otherwise.\n",
    "Therefore, stoke is not just optimized for parallelism, but also for varied hardware architecture.\n",
    "Compute clouds offer a lot of varied hardware architecture.\n",
    "It has never been easier to create a programming language.\n",
    "Moreover, there is no language that has been specifically optimized for the cloud.\n",
    "This is what you want to create.  A programming language, or more generally, a computing environment in which scientists are able to take full advantage of the cloud, both in terms of compilation time and in terms of the runtime code that it can produce.\n",
    "\n",
    "`Why do you need your own language?  LLVM optimizers work for any language, so why do you need your own front end too?`\n",
    "Because the smaller your language is, the easier it is to optimize.  Normal optimizers use a lot of heuristics on the language, but Stoke would basically do away with this.  All you have to do is specify your language to Stoke, and it will be able to optimize it.  All of those man-hours poured into C and the like are no longer an impossible hurdle to get over.  You can now have code as fast as C without having to use a bunch of guess-like optimization techniques.  So you’re no longer bound to the cumbersome syntax of C either.  Type inference, functions as data, easy vector operations, no need to adhere to 40 years worth of backwards compatibility.  With Stoke, making a new language doesn’t mean you have to sacrifice runtime efficiency.\n",
    "\n",
    "`What kinds of optimizations do you actually want to look into?`\n",
    "Stoke, as it currently is, as well as applied to GPUs and other ASICs\n",
    "Automatic parallelization in terms of threading and multiple CPUs/GPUs\n",
    "Polly, which does data locality optimizations.\n",
    "Using SMT/SAT solvers for general optimizations.\n",
    "Using software like Klee, Cyclone, CCured, and SAFECode to automatically catch even more errors.\n",
    "Runtime optimizations.  Not really sure how the cloud can help here, but big data programs by definition take in a lot of varied data, and there is no other way to optimize for that other than at runtime.\n",
    "\n",
    "Leo said when I asked about the guy at apple:  “He wasn’t on LLVM, but he was using an SMT solver, not sure which one.  But basically yeah searching for a sequence of assembly instructions than can do the same thing as another sequence but in fewer steps”.  Hm… Unrelated, Leo also said he had to use Lex and Yacc at Apple.  Why didn’t they use Antlr?  Much easier, basically the same license.  They use LLVM, which uses a pretty much identical license.\n",
    "\n",
    "`Who is this for?`\n",
    "Scientific programmers who want to perform massive computations.\n",
    "Of particular interest is machine learning, which currently uses many heuristics, not only to get better answers but also to speed up the arrival at those answers.\n",
    "...Cryptocurrency miners.\n",
    "Perhaps it won’t be the main language that scientific programmers use, but maybe it could be used to create libraries that these languages could call.\n",
    "\n",
    "`So how are you actually going to do it?`\n",
    "Right now, you need to make a toy language.  Get a feel for the whole thing.\n",
    "Then, look further into the different tools you want to use / work on.  LLVM, Stoke, Klee, and the like.  \n",
    "If for some reason you want to make your own full language specification, take a deep dive into Antlr.\n",
    "Can’t use Flex and Bison, those are GPL licensed.\n",
    "It’s important that we stick with BSD-like licenses.\n",
    "Remember Apple switch from gcc to clang because of the licensing.\n",
    "\n",
    "`How is this any different from Julia?  Go?  C?  The millions of other languages?`\n",
    "This language will be designed specifically for compiling and running on massive parallel computers.  It will attempt to be the fastest language possible.\n",
    "\n",
    "Julia was designed as ‘a fast scripting language’.  It has weird syntax.  Also, it's not that fast.\n",
    "Go was designed as a 'systems language'.  Not explicitly for fast computations.  Yes, it was designed for concurrency, but for explicit concurrency, as opposed to automatic.\n",
    "C has garbage syntax and too much to worry about in terms of backwards compatibility to get much faster.\n",
    "\n",
    "It won't go faster than all other languages in all instances.  But maybe if it goes faster than all languages in just a few instances, then it's a success.  You could make some libraries that could be called from python, and people would get some use out of it, even if they don't use it directly.\n",
    "\n",
    "Tier 2———————————————————————————\n",
    "\n",
    "`Why pay any attention to the syntax at all?  Why not stick purely to an optimizer that can take in any kind of language?`\n",
    "Because the more features your language has, the harder the search problem is.\n",
    "More features means potentially slower as well.\n",
    "Read the below link that talks about how tuples are much faster than lists in python. https://stackoverflow.com/questions/2174124/why-do-we-need-tuples-in-python-or-any-immutable-data-type\n",
    "The smaller your programming language, the smaller the surface area is that you need to optimize.\n",
    "\n",
    "https://medium.com/@simplyianm/why-gos-structs-are-superior-to-class-based-inheritance-b661ba897c67\n",
    "Skip to ‘the fragile base class problem’.  I think this explanation is good.\n",
    "\n",
    "`Writing your own programming language is pointless.  There are so many out there, and they all fail.`\n",
    "That may be true, but as long as you put most of your effort into established projects like LLVM, Stoke, Klee, and the like, your work won't be wasted.\n",
    "\n",
    "https://mortoray.com/2018/08/07/sadly-i-must-say-goodbye-to-leaf-my-programming-language/\n",
    "This guy spent years of his life on this language called leaf, and is now abandoning it.  You can learn from his mistakes.\n",
    "\n",
    "https://www.ponylang.org/discover/#what-is-pony\n",
    "A language called Pony.  “In Pony, performance is the most important thing besides correctness.”\n",
    "https://news.ycombinator.com/item?id=9482483\n",
    "Rust’s creator doesn’t like it.\n",
    "\n",
    "https://www.reddit.com/r/rust/comments/7qels2/i_wonder_why_graydon_hoare_the_author_of_rust/\n",
    "This is from the original creator of rust.  He burned out for a while.\n",
    "\n",
    "`There are so many different things you want to do.  How are you supposed to do all of this stuff?`\n",
    "For now, it’s just about exploring.  You won’t be able to do all of this stuff.  But you do want to explore it, and that’s what matters.\n",
    "\n",
    "Also, to reiterate, this is not a general purpose language.  Since it has fewer concerns than C/C++, it can be faster, and with fewer bugs.\n",
    "\n",
    "`What exactly do all the code correctness projects do for you?  Things like klee?`\n",
    "Besides making it easier to debug, it would allow your language to be based on much less safe constructs, which means they can be faster.  In other languages, they're afraid to implement 'unsafe' constructs because in the past they would lead to very difficult bugs.  But now you can have these unsafe constructs and be comfortable in the fact that they will be caught at compile time.  The cloud will also allow you to do more powerful automated testing.  Your general idea is that the power of the cloud unlocks a whole host of new opportunities for simplifying and improving the user experience with compiled languages.\n",
    "\n",
    " \n",
    "\n",
    "Tier 3———————————————————————————\n",
    "\n",
    "`Ok, just dump everything here.`\n",
    "\n",
    "What is the difference between actually understanding something vs memorizing it?  Consider regular expressions.  Most people don’t know how they are actually implemented in code.  But I bet there are people who will use regex their whole lives and understand it intuitively without knowing how it works under the hood.  What is the difference between this and someone using pytorch to do machine learning stuff, and having no idea what they’re doing?  Come to think of it, you don’t really know how a computer really adds 2 numbers together, do you?  But why don’t you feel the need to scratch that itch?  It’s because you know how to do addition by hand.  If asked to, you could match a string to a regex expression in your head using a known procedure.  If I see a \\*, I can match as many as I want.  If I see a |, I match one or the other.  But machine learning is complex.  If asked to do machine learning by hand, there is no way in hell you could do most of the coding stuff by hand.  So you don’t need to know how a computer actually does things.  All you need to know is how a human could do them by hand.  Then leave it up to the compiler writer to actually understand how a computer does it.  For all the nay-sayers, do you know how a calculator puts together numbers?  Do you fault every small business owner, accountant, and scientist who uses a calculator without knowing how it works?\n",
    "\n",
    "https://en.wikipedia.org/wiki/History_of_Python\n",
    "Very interesting.  Explains stuff like the GIL (python was originally designed for a weird operating system called Amoeba).\n",
    "\n",
    "https://www.reddit.com/r/rust/comments/55k577/rust_compilation_times_compared_to_c_d_go_pascal/\n",
    "This seems to assert that Rust can be compiled very, very fast.\n",
    "\n",
    "How to decide on software tools:  whichever is most popular.  If a google search doesn’t help, see if you can collect analytics yourself.  How many contributors does the project have?  How many pull requests?  How compatible is it with other stuff?  The compatibility thing can be found on wikipedia through charts.\n",
    "\n",
    "Metaprogramming and template metaprogramming.  “Moves computations from runtime to compile time”.  Also look at ‘convention over configuration’ on wikipedia.  Linked to on the metaprogramming page.\n",
    "\n",
    "Reflection:  another interesting concept.  But looking at it, it makes me think that this is the prototypical example of a feature that your language should not implement.  These types of features (of which I’m having a hard time describing their commonalities) are things that increase the linguistic power of the language; not the computational power.\n",
    "\n",
    "I know this is supposed to be about automatic parallelization, but I feel like a really easy way to implement locking would be to just do something like this:\n",
    "\n",
    "\tRegular code\n",
    "\n",
    "\tLOCK:\n",
    "\t\tSynced code\n",
    "\t\tSynced code\n",
    "\t\tSynced code\n",
    "\n",
    "\tRegular code\n",
    "\n",
    "This is better than lock.acquire() and lock.release() because you never have to search for where the lock is actually happening.  The indentation makes it obvious.  Of course, in C you could just do lock.acquire and lock.release, then indent every line between them since C doesn’t care about whitespace.  But nobody does that because it would look weird and generate wtfs from readers.\n",
    "\n",
    "Spark is basically for Scala.  You should look at Scala.\n",
    "\n",
    "https://stackoverflow.com/questions/6319086/are-gcc-and-clang-parsers-really-handwritten?noredirect=1&lq=1\n",
    "Even C is ambiguous.\n",
    "\n",
    "https://softwareengineering.stackexchange.com/questions/23718/whats-the-most-used-programming-language-in-high-performance-computing-and-why\n",
    "Found when googling ‘best programming language for high performance computing’.  Makes me think that a runtime optimizer is definitely important.  Is it possible if you’re not using an interpreter/virtual machine?\n",
    "\n",
    "https://lmax-exchange.github.io/disruptor/\n",
    "Paul says this is a really good white paper on ‘disruptors’, whatever those are.  Something to do with inter-process communication or something.  He says disruptors have been around for a while, but this is just a good white paper on them.\n",
    "\n",
    "https://www.reddit.com/r/programming/comments/6z6fgz/how_did_python_become_a_data_science_powerhouse/\n",
    "\n",
    "‘A performance comparison of container-based technologies for the Cloud’.  \n",
    "https://www.sciencedirect.com/science/article/pii/S0167739X16303041\n",
    "\n",
    "Wait...I remember a GoDoc saying something like it doesn’t allow implicit type coercion.  But then you have stuff like 120 * Time.minute.  Isn’t that coercion?\n",
    "\n",
    "http://llvm.org/\n",
    "See the OpenMP thing?  What does the word ‘runtime’ even mean?  Also if you look at the Go faq they use the word 'runtime' too, and even explain that their definition is different from other people's definition.\n",
    "\n",
    "http://www.zverovich.net/2016/05/13/giving-up-on-julia.html\n",
    "People say ‘oh, I don’t like Julia because it’s not as fast as they advertise’, but just look at how this person is benchmarking Julia.  Hello World?  Come on.  Of course Julia is going to be slow for tiny insignificant programs like this since it’s JIT compiled.\n",
    "\n",
    "Ok, so Julia is compiled just-in-time.\n",
    "https://agilescientific.com/blog/2014/9/4/julia-in-a-nutshell.html\n",
    "Also, notice that they say something like ‘metaprogramming can make julia faster than fortran’.  Faster to code, or faster to execute?  I’m pretty sure they mean faster to code, but would it have an effect on runtime performance?\n",
    "\n",
    "Rust used OCaml to implement its first compiler, then it was bootstrapped.\n",
    "\n",
    "Professor Aiken said Stoke only does work on basic blocks of assembly code.  Why not higher level as well?  Yeah, the search space is larger (or maybe its equivalent), but maybe from this angle you could find more 'islands' of viable solutions.\n",
    "\n",
    "No Country For Old Men:  ‘You pick the one right tool for the job.’  Or something to that effect.\n",
    "\n",
    "Google 'undefined behavior' in C.  It's not laziness.  I think it's actually an important part of what makes C fast.\n",
    "\n",
    "https://www.reddit.com/r/rust/comments/6g8v6p/seer_symbolic_execution_engine_for_rust/\n",
    "Forget the actual question, just read some of the comments.  This is the same thing as klee.  There’s even a comment about ‘super compilation’.\n",
    "\n",
    "Types are fundamental.  A class is a user defined type.  A type specifies the set of values of a variable, and the operations you can perform on it.  The user should know exactly what they can do with a piece of data at any time, and that means static typing.  Compile time errors are easier to catch than runtime errors.\n",
    "\n",
    "Professor Aiken said in Static Vs Dynamic Typing Part 1 that ‘there are a lot of fancy new type systems that haven’t been implemented yet.’  What are they?  What exactly is he talking about?\n",
    "\n",
    "If everyone spoke English and used the English alphabet, would ascii be ok for everything?  Could we constrain chars to just 8 bits?\n",
    "\n",
    "Could you potentially use your language to mine crypto?  Haha, just joking, that would be stupid.  Everyone's using crazy ASICs to mine crypto now.  But what if it makes you a gorillionaire?  Haha jk.  But srsly.\n",
    "\n",
    "Linear algebra is a kind of explicit parallelization (or more accurately, vectorization), but unlike other kinds of parallelization, this one helps programmers because it actually makes things conceptually simpler.  With that in mind, you should make matrix operations a fundamental part of the language.  Not function calls like numpy, but using operators.\n",
    "\n",
    "Check out the Go testing/benchmark library.  Interesting concept.\n",
    "\n",
    "DE Shaw's specialized hardware.\n",
    "\n",
    "Wikipedia ‘array programming’, ‘programming paradigms', 'vector programming'.\n",
    "\n",
    "Declarative languages like Prolog.  Or perhaps it's something you want to avoid.  You want a language that feels natural.\n",
    "\n",
    "The Golang regex doc contains a link comparing Go’s implementation to Perl, Python, etc.  Worth looking at.\n",
    "\n",
    "The cathedral and the bazaar.\n",
    "\n",
    "Runtime optimizations.\n",
    "\n",
    "Syntactic sugar:  pretty, also restricting.  If it restricts what you can write, its a smaller domain space, and therefore easier to optimize.  Then again, users might get confused.  “This syntactically sugared expression should be identical to this unsugared expression, but for some reason it runs faster.  What gives?”  But maybe you’re conceptualizing it wrong.  If the sugared expression really is identical, then the compiler should see no difference, right?\n",
    "\n",
    "Geoff really appreciates that React deprecates things.  They are willing to get rid of bad stuff so they don't get crushed under their own weight.  So you shouldn't be afraid to deprecate either.\n",
    "\n",
    "Why does constexpr exist in Cpp?  If we have a factorial function f(n), why do we need to say constexpr f(n) in order for Cpp to evaluate it at compile time?  If the compiler sees an f(5) somewhere in the program, it could easily just try to execute that function now.  If it works out, great, if it doesn’t, oh well, at least you’ve partially evaluated it.  I mean, there are certain implications.  Like what if the user wants to time the function.  Then it takes a long time to compile, and when they go to test the runtime it comes back as constant time.  That’s not exactly an accurate measurement.  Still, it seems like a really big waste to not do that automatically.  Perhaps another argument in favor of compilation + runtime together.\n",
    "\n",
    "Every dynamic programming algorithm has a recursive equivalent, right?  Does that mean you could auto-dynamize recursive functions?\n",
    "\n",
    "Whitespace is good not just because it’s cleaner, but because it frees up other punctuation.  Think about all the different punctuation, and how it’s wasted.  \\#, \\$, \\{\\}, etc.  Why do we use \\# in front of an include?  What is the point.  I feel like all these symbols could be put to better use.  Like for operations.  Just things you do all the time.  I feel like angle brackets really have a lot of potential.  =>, <>, ->, >>.  Lots of good stuff there.  Not so sure about pound sign.  Seriously, go nuts.  'Operators' are just fancy function calls.  That's literally it.  And why are & and | saved for bit shifting?  Who does that anymore?  I feel like it's just a leftover from the 60s-90s days when shifting bits around made things faster.  I wouldn't be so quick to replace it though.  It's not like basic math is the only thing you can do with bit shifting.  There might be some common application out there that you're forgetting.  Why waste these symbols on includes, macros, and other stuff that we rarely even use?  We should be using these for common operations.  Like isn't >> reading from a file or something in C++?  Also don't forget that ** is the cool new power operator now.  Can't forget that one.  But what about 'and/or' vs '&&\\||' debate?  'and/or' feel more natural to type.  With '&&\\||' you have to hold the shift key down, then reach above the qwerty row.  With 'and/or' it's much more natural.  Which makes me think that maybe the other operators are also awkward?  Hm.... \\* doesn't feel unnatural.  Or maybe its just that writing out 'mul' would feel really really unnatural.  Yes, you can easily overload all this stuff with macros.  But remember that there should be 1 obvious way to do something.  Make the decision for them.\n",
    "\n",
    "Remember that crow comic 'Go get is just a fancy git clone'.  Silly, but remember that pip is also a thing.  So is npm.  It seems like all the most popular languages have their own package managers.  Hm....\n",
    "\n",
    "Why doesn't Java require the use of makefiles?  Or maybe it does and you just never realized it.  But how did they do that?  It's so much easier.  Why didn't Go do that?\n",
    "\n",
    "Remember what you said about the cloud and how hardware would become more and more specialized?  How can you optimize for hardware that hasn’t come out yet?  Cluster computers are constantly changing.  How can you make something that will be able to adapt to these changes?\n",
    "\n",
    "If you ever forget why you’re doing this, remember that Jay let his comp run overnight to get pictures of fly neurons.\n",
    "\n",
    "SQL and all its implementations.  How will these be used in conjunction with this language?\n",
    "\n",
    "Hacker News article about thread 'nurseries'.\n",
    "\n",
    "Type inference.\n",
    "\n",
    "Read “Go’s Declarative Syntax”. Has a good explanation of why C pointers are how they are, and why Go is different.  Maybe instead of ‘pointers’ you could call them ‘boxes’, since you ‘open’ them to get the actual data.  Or maybe that’s too close to packages.  Maybe ‘portal’ is a better word?  But if you’re a scientist, do you even need pointers?  Actually, you know the MapReduce model takes in functions as arguments.  So scientists need functions as args.  I think that counts as needing pointers.\n",
    "\n",
    "garbage collection and its alternatives.  Specifically, I think you should go for optional garbage collection.  This way, you can write libraries and manually collect garbage while also letting your users have garbage collected automatically.  Call malloc and free 'save' and 'trash' instead.  Forget convention.  This language is for scientists, not computer scientists.  Remember that numpy for python was written in C, so python programmers get all the benefits of manual garbage collection.\n",
    "\n",
    "Containerization.\n",
    "\n",
    "Machine learning.  It's a bag of tricks.  Rather than trying to figure out which tricks are the best, just try all the tricks and see which ones give the best results.\n",
    "\n",
    "Data pipelines.  How do users scrub data, put it into a recognizable format, feed it into a program?\n",
    "\n",
    "IEEE, Posix, and potentially other standards you will have to comply with.\n",
    "\n",
    "Licensing, such as GPL vs BSD.\n",
    "\n",
    "Explicit documentation.  Document everything.  If it's not documented, it doesn't exist.  Users will get frustrated and quit.  Look at the java docs.  Those are good.  Remember at Scale there were 2 documents:  the README, and the wiki.  Nobody ever wanted to change the README because you had to go through bureaucracy to change it.  It had to be spotless before it could be added.  It was much easier to change the wiki.  You need to make documentation easy to change.  You should want to update it.  Maybe you could have some webpages that are 'set in stone' and some that are less so.  Then let users know that there's a difference.  Maybe that sounds like a 'this is right' and 'this is wrong'.  Hm...how do you make people understand the difference?\n",
    "\n",
    "Golang seems to be of particular interest these days.  A new language that is actually popular and compiled.  If you google 'most popular programming languages on github', Go is on there.  It's pretty low, but it beat out C, Swift, and Scala.  Only ones it didn't beat out were the big hitters.  Javascript, Python, Java, C++, etc.  Python is number 2 by the way.  I wonder how it did that?  If you look at 'the zen of python' I think the most important one is 'There should be one—and preferably only one—obvious way to do it.'  That is why everyone loves python.  The creator, Guido Van Possum, is the ‘benevolent dictator for life’.  I would assume this meant he had the last say on all design decisions.  How did one guys decisions lead to such unanimous satisfaction with the language?  Wouldn't different people have different preferences?  Nope, it turns out everyone perfers simplicity.  Back to Go.  Another interesting thing is that unlike Python, C++, javascript, etc, by the time Go came around there were already tools that did the same thing.  It's a systems programming language.  How did they break into the 'market' of systems programming when its already so saturated?  Well, maybe not saturated.  Dominated by C.\n",
    "\n",
    "https://jguegant.github.io/blogs/tech/meta-crush-saga.html\n",
    "This guy Jguegant made a ‘compile time game’.  He says ‘most of the computations are done during the compiler phase.'  Interesting.  How does this work?  Supposedly it’s very computationally efficient.  But also your compiler is running over and over again.  How could that possibly be efficient? \n",
    "\n",
    "Gofmt is an interesting simple tool.  Makes me think about how tools aren’t really a standard thing.  There isn’t just a compiler, and a makefile, or an interpreter.  There isn’t just a java environment or whatever.  It’s whatever you want it to be.  I feel like tools can definitely be simpler, more helpful.  Remember that lisp debugger thing that let you rewind code?  That was pretty interesting.  Why don’t other languages do that?\n",
    "\n",
    "That start up ‘Big Stream’ was doing a whole bunch of big data compiler stuff.\n",
    "\n",
    "Rust seems interesting.  Was voted ‘most loved programming language’ on stack overflow in 2016, 2017, and 2018.  Also has an interesting not-garbage-collector thing.  I think I’ve mentioned this before, but Bigstream was modifying compilers to make them better for big data or something.\n",
    "\n",
    "There's so many kinds of parallelization. SIMD and MIMD and bit level and instruction level and task level.  Multi-core and symmetric and distributed.  So so many different techniques that no one uses because it takes too long to implement.\n",
    "\n",
    "Why do we need virtual addressing?  Why can't the compiler use the physical addresses?  Wouldn't that be faster?  There's probably something you're missing here.\n",
    "\n",
    "Something on parallelism:  If we have a task that we can make parallel, the best way to do it is to parallelize at the ‘highest’ possible level that we can.  Lets say we have a big list of matrices.  Each line in our list is a row of matrices.  Lets say each row is 100 matrices, and there are 10000 rows.  You want to multiply all 100 matrices together for each row, so your task is to spit out a list of 10000 matrices.  We’ll also say you have 4 cores to do this with.  You could split it up in a number of ways.  You could have each core multiply 25 matrices together for each row, then do 4 more multiplications to get the final product.  This involves 3 splits for each row, so 30000 splits, and 3 merges for each row, so 30000 merges.  Or you could just split the rows into 4 chunks and have each core work on 2500 rows.  This is just 3 splits, and 3 merges.  Much better.  So when jobs >> workers, splitting up your workload at the highest level possible is probably the best idea.  But what about if we have the same number of workers as jobs, or workers >> jobs?  The current ‘fastest’ supercomputer in the world is Taihu Light, which has 10,649,600 total cores, or workers.  Then how would you split up the work?\n",
    "\n",
    "Another separate thought on parallel processing:  splitting up tasks takes time, any you want all of your parallel processes to finish at the same time, so maybe you should give your earlier processes a little more work, since they start earlier.  Would that make much of a difference?  Is that part of load balancing?\n",
    "\n",
    "If polly makes C++ perform 100x better on big data sets, how come we’re not hearing about it?  How come libraries like numpy aren’t suddenly 100x faster?  Isn’t Python compiled into C++?  Maybe it’s a separate project because it’s so hard to merge with the regular optimizations present in the normal optimizer.  What if you made a compiler thing that only worked on TPU’s?  Since this thing works on CPU’s, perhaps its optimizations clash with the more classical optimizations?\n",
    "\n",
    "You want ‘automatic’ parallelization.  What is automatic parallelization?  If I use numpy, is that ‘automatic’?  Why is numpy a library and not a built in thing?  I think ‘automatic’ parallelization means it’s parallelized without you having to use any libraries or fancy classes.  Just primitives.  Maybe classes too.  But still not sure.  The program must be written in a completely sequential manner.  Then the compiler automatically makes it parallel.  What does it mean for the program to be ‘sequential’?  Are matrices a special exception?  They are a concept that allows us to ‘parallelize’ something in our mind.  While it is explicit parallelization, it is simpler for us to conceptualize it in the form of a matrix than 1 by 1.  So matrices should be allowed to be in your code.  Things like writing pragma omp parallel or calling go func are definitely explicit parallelism that you shouldn’t need.  So you should compare based only on being able to use matrices, and perhaps setting compiler options.  If the user has to think 'i'm going to do it this way because I know the compiler will parallelize it', then you're doing your language wrong.  They shouldn't have to think about that.\n",
    "\n",
    "Why when you have a compiled language, the options for changing certain behaviors are always hidden behind some menu or as a compilation tag or switch.  Switches for turning on/off garbage collection, or static type checking, or automatic formatting, or whatever environment variables.  Why not just put them in your main file?  Have a file called start/main where all your configurations go.  Now you don't need to remember any terminal commands or a ton of different files.  It's all right there, in the most obvious place.  You might think 'noooo I don't want to copy and paste my config every time I make a new project.'  Well, you don't have to.  The compiler should be able to function in the normal way, or in this much easier way as well.  Now you don't need to know what a bash_rc vs a bash_profile is (which by the way are different on MacOS vs Linux).  That isn't to say that you want a bunch of conflicting compiler options.  All you want is 1 cohesive compiler option.  The MacOS of compilers.  You don't want users messing with flags and stuff.  They should basically be coding in python.\n",
    "\n",
    "When doing machine learning, why are we the ones separating pictures into learn and test sets?   I feel like it would be easier if you just give the program all the pictures and labels, then the machine decides what goes into the learning and testing sets.  The idea would be that you want the highest possible accuracy with the smallest possible learning set.  This seems like it would take exponentially more time, though.  But you want your algorithm to learn the ‘essence’ of whatever you give it.  The smaller the learning set, the more you have condensed the essence of the thing it’s trying to learn.  This might be wrong, but right now I think machine learning algorithms just divide the pictures randomly.  I don't think choosing randomly is a good idea.  There's obviously some arrangement of pictures into training / test sets that would result in the optimal way to do things in the wild.  Oh, here's an application of making your training sets smaller: you can retrain much faster.  It would be a way to filter out the useless / bad data.\n",
    "\n",
    "Haskell and Erlang.  What are they?  What is functional programming?  It sounds they just took regular programming and removed all the conveniences.\n",
    "\n",
    "If Stoke can easily optimize anything, does that mean you could easily create a graphics library?  If you can optimize general code for a GPU, doesn't that mean it would be really easy to optimize graphical code for a GPU?\n",
    "\n",
    "Notes from PhD Grind———————————————————————————\n",
    "Page ??? (The entirety of year 1):  What you might end up like if you pursue a Ph.D\n",
    "\n",
    "Page 22:  Send cold emails.\n",
    "\n",
    "Whats the problem?\n",
    "What’s my proposed solution?\n",
    "What compelling experiments can I run to demonstrate the effectiveness of my solution?\n",
    "\n",
    "Page 23:\n",
    "\n",
    "Professors are motivated by having their names appear on published papers, and computer science conference papers usually need strong experiments to get accepted for publication. Thus, it’s crucial to think about experiment design at project inception time.\n",
    "\n",
    "Page 30:\n",
    "\n",
    "I cannot re-emphasize this point enough times: Properly calibrating your pitch to the academic sub-community you’re targeting is crucial for getting a paper accepted.\n",
    "\n",
    "Page 35-36:\n",
    "\n",
    "Make sure you and your advisor actually have similar goals in mind.\n",
    "\n",
    "Page 37-38:\n",
    "\n",
    "The horror.  Years and years for no results.  Also, remember that this is Stanford.  The place you want to go.  Also note that he’s making ‘incremental’ improvements to the already existing Klee stuff.  That’s basically what you want to do.  Just assemble a whole bunch of stuff that already exists.  You’re not really doing ground-breaking work, just implementing other people’s work.  Potentially with modifications, but still.  You can’t make a paper out of this.  Well, maybe you could, but it would be difficult.  And you would be on a timer.  And you would have to capitulate to the professor.  Ugh.  There’s no time for that.  You don’t need to publish a paper, you need to publish a language.  But wasn’t Julia someone’s research project?  Hm… doesn’t seem like it.  But you want control.  You need to be able to make all of the decisions, right now.  What you want to make is a product.  It’s not truly an exploration of new ideas, it’s a synthesis of ideas into something real.  And do those people go to grad school?  No, they just make it.  You can’t be wasting your time with some feet-on-desk professors half-assed ideas.\n",
    "\n",
    "Page 43:\n",
    "Marketing buzzwords.  Required to publish papers.\n",
    "\n",
    "Page 47:\n",
    "Online submission forms are black holes. Anything is better than blindly submitting online.\n",
    "\n",
    "53:  Search the web for related work.  Very important.\n",
    "\n",
    "58:  It turns out that ignoring your instructors and doing whatever you want is what makes you the most productive.  As you already knew.  “Those three years—my latter half of grad school—were the most creative and productive of my life thus far, in stark contrast to my meandering first half of grad school”\n",
    "\n",
    "63:  If you are a computer science researcher, your work will never be directly used in practice.  You simply don’t have the time to get things up to the production-level standards required for people to actually want to use your thing.  “To convince someone to try IncPy, I would need to guarantee that it works better than regular Python in all possible scenarios.”  Well, that’s your language, right?  All you have to do is put colons in front of all of your variable assignments, then instead of doing python <myfile>, you do sanic <myfile>.  Of course, gross oversimplification, but still.\n",
    "\n",
    "65:  Dependency conflicts are annoying.  The more integrated your stuff is with code that already exists, the more screwed you are.  What kinds of things will you have to depend on?\n",
    "\n",
    "69:  Your scholarships are on a timeline so you’re on your own if you don’t publish a bunch of papers right away.  So they make you waste your time with useless classes and bad research, then tell you that you can’t graduate unless you shit out a bunch of papers.\n",
    "\n",
    "70:  This incPy thing turned out to be one of the components of a jupyter notebook, in a way.  You run some code, you see the output, you can refer to that same code later.  This makes me think that your language needs something like that.  That might be difficult considering your language is compiled.  Or would it be difficult?  It looks like jupyter works with Go, so it shouldn’t be too bad.\n",
    "\n",
    "73:  Jupyter isn’t just really convenient, in a lot of ways it’s essential.  You need to be able to reproduce your research, not just present it.  How can you run programs really really fast when you’re in a Jupyter notebook?\n",
    "\n",
    "74:  ‘Why not make it a general application?’  Because the larger your audience is, the less you will be able to deliver to them.\n",
    "\n",
    "74-75:  ‘Why hadn’t anyone thought of this yet?’  He says he googles it and doesn’t get much back, but this seems like Containers to me.  It’s just containers.  \n",
    "\n",
    "76:  “I’ll always miss those purer times. In my current job, there’s no way I can block off three weeks just to code non-stop!”  HMMMMMM….  Maybe get a different job?  Well, he’s probably happy where he is, but you wouldn’t be.\n",
    "77:  “This is a very important point. It’s not our job as academics to ship polished products; that’s the role of companies.”  You want to ship a polished product.\n",
    "\n",
    "80-81:  He got an offer to just work on his open source project at Google.  Just get paid money to do what he had been previously doing.\n",
    "\n",
    "87:  This isn’t the first place this is mentioned, but “And without motivated students to grind through the tough manual labor, it’s impossible to get respectable publications.”  Your thing will consist of a lot of tough manual labor.  \n",
    "\n",
    "88:  Creative freedom is not to be found anywhere.  Freedom to simply work on what interests you is also not to be found anywhere.\n",
    "\n",
    "90:  Living arrangement matters for your productivity.\n",
    "\n",
    "92-93:  An example of the constant state you want to achieve.  Also note that this guy made that one environment diagram program that is useful.  Getting used to new things is a difficult, frustrating process.  You have to push through that to get to the good part.  Of particular importance:  “After years of grinding on uncertain and failed projects earlier in grad school, I now felt invigorated working intensely towards a target that I knew I could feasibly achieve.”  You’re motivated by this compiler thing because it seems so obvious, so simply achievable to you.  Maybe not an easy task, but definitely a task that is possible.\n",
    "\n",
    "100:  Produce results.  Not just for other, but for yourself, in order to stay motivated.  Also read the rest of the lessons, they seem very insightful.  Especially point 20.  Sad to say that effort alone isn’t enough.  You need to apply the right kind of effort.\n",
    "\n",
    "Last Page:  He says that it was fulfilling, etc, etc.  But he makes a compelling argument for you not to pursue a graduate degree.  Working towards a graduate degree will force you to work hard.  Do you need someone to force you to work hard?  No.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
