{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tier 0———————————————————————————\n",
    "Just skip directly to STOKE after you finish the class.  Working with search-based optimization will be the same no matter what language you’re working in.  It’ll all by LLVM bytecode.  This is the part that gets you excited.  Don’t put it off.\n",
    "\n",
    "Wait, this may be wrong.  In order to optimize things, you need to know what you’re optimizing.  You need to understand the whole thing before you go making changes to it.\n",
    "\n",
    "Tier 1———————————————————————————\n",
    "\n",
    "`What do you want to do?`\n",
    "You want a language that goes as fast as possible.\n",
    "How are you going to achieve that?\n",
    "The cloud allows anyone (with money) to easily access parallel computers.\n",
    "This means that all programs, compilers included, can be much more powerful.\n",
    "Things like stoke and klee can take advantage of this.\n",
    "Furthermore, stoke can take advantage of different hardware architectures.\n",
    "The cloud offers a lot of powerful architecture that you could not get otherwise.\n",
    "Therefore, stoke is not just optimized for parallelism, but also for varied hardware architecture.\n",
    "Compute clouds offer a lot of varied hardware architecture.\n",
    "It has never been easier to create a programming language.\n",
    "Moreover, there is no language that has been specifically optimized for the cloud.\n",
    "This is what you want to create.  A programming language, or more generally, a computing environment in which scientists are able to take full advantage of the cloud, both in terms of compilation time and in terms of the runtime code that it can produce.\n",
    "\n",
    "`Why do you need your own language?  LLVM optimizers work for any language, so why do you need your own front end too?`\n",
    "Because the smaller your language is, the easier it is to optimize.  Normal optimizers use a lot of heuristics on the language, but Stoke would basically do away with this.  All you have to do is specify your language to Stoke, and it will be able to optimize it.  All of those man-hours poured into C and the like are no longer an impossible hurdle to get over.  You can now have code as fast as C without having to use a bunch of guess-like optimization techniques.  So you’re no longer bound to the cumbersome syntax of C either.  Type inference, functions as data, easy vector operations, no need to adhere to 40 years worth of backwards compatibility.  With Stoke, making a new language doesn’t mean you have to sacrifice runtime efficiency.\n",
    "\n",
    "`What kinds of optimizations do you actually want to look into?`\n",
    "Stoke, as it currently is, as well as applied to GPU code.\n",
    "Automatic parallelization in terms of threading and multiple CPUs/GPUs\n",
    "Polly, which does data locality optimizations.\n",
    "Using SMT/SAT solvers for general optimizations.\n",
    "Using software like Klee, Cyclone, CCured, and SAFECode to automatically catch even more errors.\n",
    "Runtime optimizations.  Not really sure how the cloud can help here, but big data programs by definition take in a lot of varied data, and there is no other way to optimize for that other than at runtime.\n",
    "\n",
    "Leo said when I asked about the guy at apple:  “He wasn’t on LLVM, but he was using an SMT solver, not sure which one.  But basically yeah searching for a sequence of assembly instructions than can do the same thing as another sequence but in fewer steps”.  Hm… Unrelated, Leo also said he had to use Lex and Yacc at Apple.  Why didn’t they use Antlr?  Much easier, basically the same license.  They use LLVM, which uses a pretty much identical license.\n",
    "\n",
    "`Who is this for?`\n",
    "Scientific programmers who want to perform massive computations.\n",
    "Of particular interest is machine learning, which currently uses many heuristics, not only to get better answers but also to speed up the arrival at those answers.\n",
    "...Cryptocurrency miners.\n",
    "Perhaps it won’t be the main language that scientific programmers use, but maybe it could be used to create libraries that these languages could call.\n",
    "\n",
    "`So how are you actually going to do it?`\n",
    "Right now, you need to make a toy language.  Get a feel for the whole thing.\n",
    "Then, look further into the different tools you want to use / work on.  LLVM, Stoke, Klee, and the like.  \n",
    "If for some reason you want to make your own full language specification, take a deep dive into Antlr.\n",
    "Can’t use Flex and Bison, those are GPL licensed.\n",
    "It’s important that we stick with BSD-like licenses.\n",
    "Remember Apple switch from gcc to clang because of the licensing.\n",
    "\n",
    "`How is this any different from Julia?`\n",
    "Julia was designed as ‘a fast scripting language’.\n",
    "This language will be designed specifically for compiling and running on massive parallel computers.  It will attempt to be the fastest language possible.\n",
    "\n",
    "Tier 2———————————————————————————\n",
    "\n",
    "`Why pay any attention to the syntax at all?  Why not stick purely to an optimizer that can take in any kind of language?`\n",
    "Because the more features your language has, the harder the search problem is.\n",
    "More features means potentially slower as well.\n",
    "Read the below link that talks about how tuples are much faster than lists in python. https://stackoverflow.com/questions/2174124/why-do-we-need-tuples-in-python-or-any-immutable-data-type\n",
    "The smaller your programming language, the smaller the surface area is that you need to optimize.\n",
    "\n",
    "https://medium.com/@simplyianm/why-gos-structs-are-superior-to-class-based-inheritance-b661ba897c67\n",
    "Skip to ‘the fragile base class problem’.  I think this explanation is good.\n",
    "\n",
    "`Writing your own programming language is pointless.  There are so many out there, and they all fail.`\n",
    "That may be true, but as long as you put most of your effort into established projects like LLVM, Stoke, Klee, and the like, your work won't be wasted.\n",
    "\n",
    "https://mortoray.com/2018/08/07/sadly-i-must-say-goodbye-to-leaf-my-programming-language/\n",
    "This guy spent years of his life on this language called leaf, and is now abandoning it.  You can learn from his mistakes.\n",
    "\n",
    "https://www.ponylang.org/discover/#what-is-pony\n",
    "A language called Pony.  “In Pony, performance is the most important thing besides correctness.”\n",
    "https://news.ycombinator.com/item?id=9482483\n",
    "Rust’s creator doesn’t like it.\n",
    "\n",
    "https://www.reddit.com/r/rust/comments/7qels2/i_wonder_why_graydon_hoare_the_author_of_rust/\n",
    "This is from the original creator of rust.  He burned out for a while.\n",
    "\n",
    "`There are so many different things you want to do.  How are you supposed to do all of this stuff?`\n",
    "For now, it’s just about exploring.  You won’t be able to do all of this stuff.  But you do want to explore it, and that’s what matters.\n",
    "\n",
    "Also, to reiterate, this is not a general purpose language.  Since it has fewer concerns than C/C++, it can be faster, and with fewer bugs.\n",
    "\n",
    "`What exactly do all the code correctness projects do for you?  Things like klee?`\n",
    "Besides making it easier to debug, it would allow your language to be based on much less safe constructs, which means they can be faster.  In other languages, they're afraid to implement 'unsafe' constructs because in the past they would lead to very difficult bugs.  But now you can have these unsafe constructs and be comfortable in the fact that they will be caught at compile time.  The cloud will also allow you to do more powerful automated testing.  Your general idea is that the power of the cloud unlocks a whole host of new opportunities for simplifying and improving the user experience with compiled languages. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Important question you have to ask yourself:  how do you model a computer now?  Computers aren’t just a monitor, a cpu, caches, physical memory, buses, etc.  It’s more general than that.  It’s not just a cpu, there’s a whole range of chips that can perform computations.  And it’s not just 1 chip, it’s many chips.  How does machine code get translated in such a way that it fully utilizes the available hardware?  How do you build a system that can optimize for a machine that is constantly evolving and growing?  Kind of thinking about ASICs with this last part.  And a more general question:  how do you solve a problem, and keep it solved?  By this, I mean the fact that we tend to write code that does the same, or very similar things, over and over again.  Python is popular because it has 1 and only 1 solution for everything.  All of this research is doing that right now.  You’re solving problems that have already been solved.  How do you solve it in a way such that it will stay solved?\n",
    "\n",
    "Wait.  If a monte carlo optimizer just uses search to find the best solution, then it doesn’t need to ‘understand’ the problem, right?  As in, you don’t have to put in hours and hours of grinding on heuristics to make it work.  So you don’t need nearly as much knowledge of the architecture.  You don’t have to think about each individual case.  Here’s the thing:  wouldn’t this mean you could do the exact same with a GPU?  Get its instruction set, then you could include all the GPU instructions in all your random guessing.  Automatic GPU utilization, and you don’t even have to do much fancy stuff for it.  Damn, you’ve said this before, but all of this is going to sound really naive once you actually know what you’re doing.\n",
    "\n",
    "If your compiler just take the program and uses it as a test case or whatever, could you do Prolog stuff?  The program tells you what it wants, and how it wants you to do it, and you just throw away all the ‘how’ and start over.  Isn’t that Prolog?  Remember that Prolog is for AI stuff.  Machine learning is a kind of AI.  It might not just be cool.  It might be useful.  Yes, it’s a little out there.  But this random optimizer makes it seem feasible to have something like this.  It wouldn’t be too much more work in the back end.  Just the frontend; adding the syntax to be able to do it.  Assuming your idea about this Prolog thing actually makes sense, it reveals something deeper about monte carlo optimization:  it removes the need for control in your language, since optimization doesn’t depend on it.  Anything that isn’t pure logic is purely for conceptual clarity for the programmer.  But you’re probably completely wrong about this.\n",
    "\n",
    "It’s not necessarily to develop the fastest language, but to learn about the different compiler techniques.\n",
    "\n",
    "Riscy since it’s unsafe and goes almost as fast as native risc.\n",
    "\n",
    "You said something like this earlier, but maybe your language wouldn’t be a direct competitor to Julia.  Maybe it could potentially be a backend callee for Julia.  Remember that C, Rust, and Go are ‘general purpose’.  This is purely for performance.  Alternatively ‘code that is compiled on the cloud and targeted anywhere.’  Developers all have access to large computers, but users don’t.  This language creates programs that take advantage of the cloud during compile time (and also runtime, potentially).  It is general purpose in its syntax, big data in its semantics.  Stuff like Scala and hadoop.  Who is that for?  Data scientists don’t want to deal with that.  Why make huge projects based on these things.  That just adds to the learning curve.  You shouldn’t learn tools.  It’s not flexible at all.  Code is flexible.  ‘Now that we have access to the cloud, we can do compiler optimizations that before were infeasible due to time constraints.’\n",
    "\n",
    "https://softwareengineering.stackexchange.com/questions/23718/whats-the-most-used-programming-language-in-high-performance-computing-and-why\n",
    "Found when googling ‘best programming language for high performance computing’.  Makes me think that a runtime optimizer is definitely important.  Is it possible if you’re not using an interpreter/virtual machine?\n",
    "\n",
    "https://lmax-exchange.github.io/disruptor/\n",
    "Paul says this is a really good white paper on ‘disruptors’, whatever those are.  Something to do with inter-process communication or something.  He says disruptors have been around for a while, but this is just a good white paper on them.\n",
    "\n",
    "https://www.reddit.com/r/programming/comments/6z6fgz/how_did_python_become_a_data_science_powerhouse/\n",
    "\n",
    "‘A performance comparison of container-based technologies for the Cloud’.  \n",
    "https://www.sciencedirect.com/science/article/pii/S0167739X16303041\n",
    "\n",
    "Think about context sensitive grammars.  Does GLR mean context sensitive?  The ease and simplicity with which you can specify your language is much, much more important than the time it takes to parse the language.  So you should start by figuring out the easiest way to specify a programming language, then afterward work on how you can make the grammar faster to parse.  Someone said ‘we’ve been solving the wrong problems in parsing.’  Rather than thinking ‘this grammar will take n^2 time to parse’ think ‘3 out of these 100 grammar rules will take n^2 time to parse.  The other 97 take n time.’  The runtime of each individual grammar rule is more important.  But do not actually make anything like this.  You want a fast, practical programming language.  Not a fast, practical programming language generator.  There might be some tool out there that no one uses where the creators of the tool would love for you to use it.  Perhaps you could even work with someone who is currently working on that.  Cobble something together using known tools that do EXACTLY what you want without getting in the way.\n",
    "\n",
    "Wait...I remember a GoDoc saying something like it doesn’t allow implicit type coercion.  But then you have stuff like 120 * Time.minute.  Isn’t that coercion?\n",
    "\n",
    "Another important thing about Go:  you can’t necessarily say this for the other languages, but Go was created by people with experience.  Compare Go to a different language.  What are the differences in the decisions they make?\n",
    "\n",
    "https://en.wikipedia.org/wiki/Criticism_of_C%2B%2B\n",
    "You don’t have the experience that the Go guys have.  You need to learn from their mistakes WITHOUT repeating them.\n",
    "\n",
    "‘We currently perform classical loop transformations, especially tiling and loop fusion to improve data-locality. ‘  This is from their front page.  This seems like a bunch of heuristics.  I feel like you should understand more of the basics, and more of the theory, before you dive into these seemingly unproven (though no doubt effective) methods.\n",
    "\n",
    "\n",
    "On optional garbage collection:  You’ll have to do it if you want performant code.  Maybe users won’t turn off garbage collection, but the libraries they use should be fast.  You can’t get fast libraries without collecting all your garbage manually.  Would it really be that hard to mix the two?  You have python able to call native C.  \n",
    "\n",
    "\n",
    "What is the difference between actually understanding something vs memorizing it?  Consider regular expressions.  Most people don’t know how they are actually implemented in code.  But I bet there are people who will use regex their whole lives and understand it intuitively without knowing how it works under the hood.  What is the difference between this and someone using pytorch to do machine learning stuff, and having no idea what they’re doing?  Come to think of it, you don’t really know how a computer really adds 2 numbers together, do you?  But why don’t you feel the need to scratch that itch?  It’s because you know how to do addition by hand.  If asked to, you could match a string to a regex expression in your head using a known procedure.  If I see a *, I can match as many as I want.  If I see a |, I match one or the other.  But machine learning is complex.  If asked to do machine learning by hand, there is no way in hell you could do most of the coding stuff by hand.  So you don’t need to know how a computer actually does things.  All you need to know is how a human could do them by hand.  Then leave it up to the compiler writer to actually understand how a computer does it.  For all the nay-sayers, do you know how a calculator puts together numbers?  Do you fault every small business owner, accountant, and scientist who uses a calculator without knowing how it works?\n",
    "\n",
    "I forgot where I heard this, but a compiler should ‘do hundreds of passes’.  This makes it easier to do a number of things.\n",
    "\n",
    "https://en.wikipedia.org/wiki/History_of_Python\n",
    "This is how python was made.  How did the Guido guy get into this place so that he could make python?\n",
    "\n",
    "Sanic VS Julia:  Sanic is faster, as it is compiled separately, at the cost of being statically typed.\n",
    "Sanic VS C++:  Sanc will hopefully be faster, but if not, still has a much nicer syntax than C++.\n",
    "Sanic VS Rust:  This is one that I’m not sure about.  Sanic has nicer syntax.\n",
    "So all I have to do is make sure that Sanic is actually faster, or at least comparable, to these languages.  So what am I sacrificing in order to get this speed?  You can’t do any systems type stuff.  Rust and C++ are systems programming languages.  All Sanic does is go fast on numbers, functions, and objects.  That, and you have one advantage that they don’t have:  you have 0 technical debt.  Julia’s technical debt is its dynamic type system and lack of separate compilation (which they think of as a good thing).  Rust’s debt is that it is developed by a corporation.  I don’t think I need to say what C++’s technical debt is.  Perhaps you should think about the cloud computing angle more.\n",
    "\n",
    "I feel like you should NEED a file called main to start at.  Then you should also have a config file.  Well, not actually.  The config should go in main.  Like ‘this uses garbage collection’ or not.  Better to state it on a per-project basis rather than system wide.\n",
    "\n",
    "https://blog.golang.org/constants\n",
    "Type conversions are a problem that you are going to run into.  If you don’t make the right decision about how to handle them, it could get ugly.  But then again it seems kind of dumb that people would even use something like ‘long signed int’.  Like, what?  How many bytes do you need?  Just call it by that.  In fact, all your types should just be int.  A 64 bit thing is a dint.  A double int.  A 128 bit thing is a ddint.  A double double int.  A 16 bit thing is a hint.  A half int.  An 8 bit thing is a hhint.  A half half int.  But you should also have a special 8 bit thing for characters.  NOT 16 bit.  If people want to use the extended character set, just give them a 32-bit version.  Because I think java did 16 bit, and it ended up not being enough.  So they can either use ASCII like a normal human being, or they can use full 32 bit whatevers for their special text.  Oh, and don’t forget floats.  Floats are 32 bit.  Dfloats are 64 bit.  Hfloats are 16 bit.  The only problem is:  signed or unsigned?  I feel like unsigned shouldn’t even be a thing.  If you want to force things to be >= 0, that’s your problem.  Oh, but unsigned gives you twice the range!  Yeah, if you think you need ‘twice’ the range now, you’re going to need 4 times the range soon.  Don’t use unsigned.  Just byte the bullet and add another d to your type.  Or you could do it the rust way:  i8, i16, i32, etc.  Seems better that way.  Explicit.  No need to convert anything in your head.  It just tells you how long it is.  f16, f32, etc.  Chars, I think, are a special case.  You have ASCII, which requires 8 bits, but should you include a c16?  Java uses c16’s and now they’re hurting for c32’s.  If you choose the next character set to be 32 bits for each character code, should c16’s exist, or will that just confuse people?\n",
    "\n",
    "All this stuff about optimizations.  Does it have anything to do with ‘control’ theory?  Since programs are just logic + control?  Also seems to have a lot more to say about optimizations.\n",
    "\n",
    "Writing your own lexer and parser vs using a Flex + Bison:\n",
    "Writing your own means you have more control.  Could potentially be faster.  Will almost definitely be slower.  Will be a lot of work.  Will hopefully let you understand the inner workings better.  Could get lost in the details.\n",
    "Using Flex + Bison.  Will almost certainly be faster.  Will also be much, much easier to code.  Although C and C++ use their own lexer and parser, other languages like Ruby use a generator.  \n",
    "I feel like gcc and clang are hand written just because C and C++ are so incredibly bloated.\n",
    "A third option:  Create your own lexer / parser generator.  I feel like this could potentially be a good solution long term.  You would get flexibility as well as speed.  Considering that Flex and Bison are super old, maybe you could make a better one.  The Bison spec says “For historical reasons, Bison by default is limited by the additional restrictions of LALR(1), which is hard to explain simply. …. As an experimental feature, you can escape these additional restrictions by requesting IELR(1) or canonical LR(1) parser tables.”  So I know for a fact that Bison has some garbage in it.  Also, remember how bad the Flex documentation was?  Before you think ‘but there are already so many tools out there’ do you understand those tools?  Would they give you exactly what you needed?  You want to make a programming language.  That’s a huge project, and a programming language has a lot of nuance to it.  Right now I kind of feel like you should definitely use Flex + Bison for now, and in the future possibly consider making your own lexer + parser generator.  If you do both, I’m sure there’s some further optimizations that you could do.  As another note about making your own generator, it’s in line with the spirit of the language you want to make.  You don’t want to hand optimize things.  You want the optimizations to happen automatically.  That’s something that a generator thing could take care of.  Also Bison says it can support GLR, but it’s ‘supported’, which to me doesn’t sound like an integral feature.  Your ideal lexing + parsing tool is like this:  it would allow you to specify any shitty grammar, and it would run.  It would allow you to easily output error messages when needed.  It would have a simple syntax and instructions.  And it would give you suggestions.  It would say something like ‘Your grammar is LR(*) right now.  It will take X seconds to run on most inputs.  We can automatically make it LR(1) for you.”  So you have the option to make it faster.  This way, you understand your grammar better.  \n",
    "Here’s some literature to read: \n",
    "https://softwareengineering.stackexchange.com/questions/17824/should-i-use-a-parser-generator-or-should-i-roll-my-own-custom-lexer-and-parser\n",
    "https://mortoray.com/2012/07/20/why-i-dont-use-a-parser-generator/\n",
    "\n",
    "\n",
    "Consider all the crazy data structures that no one ever implements because it’s just too much work and an array is faster to code.  A compiler would actually want to use data structures like this, right?  It’s code that’s being run all the time.  Before you say ‘table driven is fast, dumb, and easy’, consider that memory isn’t unlimited, and on top of that tables might not necessarily be the simplest thing conceptually to apply to a problem.  Look at Cuckoo filters.  They’re new, 2014 to be exact.  They’re probabilistic.  You could use your EE126 knowledge there.  There must be some way to apply this to compiler optimization.  I feel like there’s a way to apply just about anything to compiler optimization.  Come to think of it, it seems like probability should be an important factor in future optimizations.  If your data is random, you pretty much need to use probability in order to load balance.  How do you make sure that each CPU is getting approximately equal amounts of work?  There’s also that language whose base structure is a tree instead of an array, Refal.\n",
    "\n",
    "https://www.reddit.com/r/rust/comments/55k577/rust_compilation_times_compared_to_c_d_go_pascal/\n",
    "This seems to assert that Rust can be compiled very, very fast.\n",
    "\n",
    "Thought:  Everything that isn’t pure functional programming is syntactic sugar.  For loops, variable declarations, etc.  Someone proved that you can do anything with functional programming, right?\n",
    "\n",
    "Let’s say you make your own language, and it really does do everything you want.  Now you have to sell it.  Well, not sell it, but get people to pick it up.  How do you do that?  Make something cool.  Hm...what’s cool?  Hint:  a game.\n",
    "\n",
    "Design is figuring out what you want to be a limitation, and what you want to be a maximization.  Do you want to maximize the comfort of a car while simultaneously making sure it can go at least 100mph?  Or do you want to maximize the speed of the car while also making sure it’s comfortable enough to sit in for a few hours?  Could result in similar designs, could result in very different designs.\n",
    "\n",
    "How to decide on software tools:  whichever is most popular.  If a google search doesn’t help, see if you can collect analytics yourself.  How many contributors does the project have?  How many pull requests?  How compatible is it with other stuff?  The compatibility thing can be found on wikipedia through charts.\n",
    "\n",
    "Metaprogramming and template metaprogramming.  “Moves computations from runtime to compile time”.  Definitely worth looking into.  But also computations for big data are based on the data, which isn’t given until runtime.  Also look at ‘convention over configuration’ on wikipedia.  Linked to on the metaprogramming page.\n",
    "\n",
    "Reflection:  another interesting concept.  But looking at it, it makes me think that this is the prototypical example of a feature that your language should sacrifice (as in not implement).  These types of features (of which I’m having a hard time describing their commonalities) are things that increase the linguistic power of the language; not the computational power.  These are the types of things that you do not need, it seems like.\n",
    "\n",
    "I feel like computation itself can be shown to be a tree.  Like a math computation.  If you can figure out the tree, shouldn’t it be relatively simple to figure out how to parallelize it?\n",
    "\n",
    "I know this is supposed to be about automatic parallelization, but I feel like a really easy way to implement locking would be to just do something like this:\n",
    "\n",
    "\tRegular code\n",
    "\n",
    "\tLOCK:\n",
    "\t\tSynced code\n",
    "\t\tSynced code\n",
    "\t\tSynced code\n",
    "\n",
    "\tRegular code\n",
    "\n",
    "This is better than lock.acquire() and lock.release() because you never have to search for where the lock is actually happening.  The indentation makes it obvious.  Of course, in C you could just do lock.acquire and lock.release, then indent every line between them since C doesn’t care about whitespace.  But nobody does that because it would look weird and generate wtfs from readers.\n",
    "\n",
    "“How do I minimize the number of poor design decisions I make?”  This is an incredibly broad question, but still one worth asking.  Obviously, the more time you spend on making a design decision, the less likely you are to make a poor one.  But of course, you have limited time on this earth, and so must make decisions with some amount of haste.  There’s the obvious things to do:  consult someone with experience.  But you can’t always go with what they say.  Otherwise you’ll just end up with nothing new.\n",
    "\n",
    "Another argument for optional garbage collection:  say you wanted to write a really fast machine learning library.  Kind of hard to do that with garbage collection, right?  Sure, you could write it in C, but that would defeat the purpose, wouldn’t it?\n",
    "\n",
    "The wikipedia entry for GLR parsers say that an alternative name is ‘parallel parser’.  This sounds promising.  There was also this guy on stack overflow who said GLR parsers were great.  Also, while they run in n^3 time on ambiguous grammars (the parsers you know can’t run at all on ambiguous grammars) they still run in n time on non-ambiguous grammars.  This sounds fantastic.  N time when you can, but can also take ambiguous grammars, and also seems like it’s easily parallelizable.\n",
    "\n",
    "Alternative if else:\n",
    "X ?= 4:\n",
    "\tReturn x\n",
    "\tReturn y\n",
    "Not perfect, doesn’t cover everything, bad idea by itself, but better than ternary operator because of readability.  Or maybe some easy way to combine this with switch statements?\n",
    "\n",
    "A thought on static typing:  you read somewhere that programming is logic + control, right?  And supposedly, less control is better.  A language like prolog is basically all logic and no control.  The less state, the more functional the language is, the more pretty.  I would argue that static typing falls into the logic portion more than the control portion.  Think of static typing as delineating the set that a variable belongs to in a mathematical equation.  It’s like saying f(x) = bla bla where x is an element of the natural numbers.  You could leave it off for conciseness, yes, but people mostly leave it out once it’s already been defined in some earlier mathematical equation.  In programming, you’re always creating functions that the user hasn’t seen before, in essence creating new proofs all the time, so it’s better to be statically typed.  Another argument is that you can include much better error messages, which is actually easier for the user.  Also the auto keyword is really hot right now, so it’s really not that big a deal.\n",
    "\n",
    "You should have 2 settings for debug output:  beginner, advanced.  Beginner basically talks in plain english.  Advanced is much more concise, like other debug output.  The reason you might want more concise debug output is because for big projects there’s a lot of debug output.  Instead of 80 lines, you might get 400 lines.  A lot more scrolling.  Kind of annoying.\n",
    "\n",
    "Refal - A language where the basic data structure is a tree, rather than a list.  Allows for more freedom.  That’s all I know about this, but it sounds interesting.\n",
    "\n",
    "Spark is basically for Scala.  You should look at Scala.\n",
    "\n",
    "Ask the super node guys more questions.  You need to get an advisor.  You need to find an advisor whose research lines up with what you want to do.  2 years of classes, 2 years of hard research, X years before you get a stamp from your advisor.  Your advisor determines what you work on.  Then you tell the advisor that you want to change it a little bit, and maybe the advisor says ok.  Your advisor pays you.  Your advisor gets grants.  Most advisors are professors.  There are some advisors who are at Berkeley National Lab.  “How to find a research advisor”.  Do you get into grad school, then find an advisor, or do you get an advisor, then get into grad school?  Yes.  But really, probably more likely to get in if you get an advisor first.  Ask professors working on cloud, on compilers, and on parallelism / distribution.\n",
    "\n",
    "Resource\n",
    "https://stackoverflow.com/questions/6319086/are-gcc-and-clang-parsers-really-handwritten?noredirect=1&lq=1\n",
    "Even C is ambiguous.  You should avoid operator overloading when possible.  Also avoid all the crazy shit that C allows.\n",
    "\n",
    "Goal\n",
    "Model your optimizations as constraint satisfaction problems.  I feel like most people know how to do this, but they never formally learned the actual algorithm and they just have a big switch statement.  Actually, Professor Aiken mentioned that all these optimizations can be modeled as a search problem.  Is a constraint satisfaction problem a search problem?  I think so.  Speaking of search problems, Prolog is good for that, right?  Is it at all possible for you to just mash prolog-like functionality into a regular imperative language?  Would that be at all helpful?  Would it just be confusing?  Would it be easier, or harder to optimize?\n",
    "\n",
    "Goal\n",
    "Basic principle of coding:  If the programmer isn’t forced to do it, they won’t do it.  This means code is never optimized.  Tools that aren’t mandatory aren’t used.  There are compiler options beyond -o3.  They aren’t used for fear of introducing bugs and dependencies.  So you need to make the decision for them.  This is not a general purpose language.  Look at polly, and all the bug fixes it requires.  \n",
    "\n",
    "Goal\n",
    "Write out why you think a brand new language is necessary / helpful to big data programmers.  Why does it need to be separate, what does it have that other languages don’t?\n",
    "\n",
    "Goal\n",
    "Make a generic letter to professors.  Hi professor, I’m Miles. I enjoyed your work on _, and had some questions about it.  (Ask questions here).  The reason Im interested because of this idea I had for a programming language.  (Insert research pitch here).  What do you think?  Use your letter to Nick as a reference.  Maybe include a demo showing that it ran fast.\n",
    "\n",
    "Goal feature\n",
    "Since the cloud has very limited hardware, you can optimize for that specific hardware.\n",
    "\n",
    "Tier 3———————————————————————————\n",
    "\n",
    "http://llvm.org/\n",
    "See the OpenMP thing?  What does the word ‘runtime’ even mean?\n",
    "\n",
    "http://www.zverovich.net/2016/05/13/giving-up-on-julia.html\n",
    "People say ‘oh, I don’t like Julia because it’s not as fast as they advertise’, but just look at how this person is benchmarking Julia.  Hello World?  Come on.  Of course Julia is going to be slow for tiny insignificant programs like this since it’s JIT compiled.\n",
    "\n",
    "Ok, so Julia is compiled just-in-time.\n",
    "https://agilescientific.com/blog/2014/9/4/julia-in-a-nutshell.html\n",
    "Also, notice that they say something like ‘metaprogramming can make julia faster than fortran’.  Faster to code, or faster to execute?  I’m pretty sure they mean faster to code, but would it have an effect on runtime performance?\n",
    "\n",
    "Rust used OCaml to implement its first compiler, then it was bootstrapped.\n",
    "\n",
    "Professor Aiken said Stoke only does work on basic blocks of assembly code.  Why not higher level as well?  Yeah, the search space is larger (or maybe its equivalent), but maybe from this angle you could find more 'islands' of viable solutions.\n",
    "\n",
    "No Country For Old Men:  ‘You pick the one right tool for the job.’  Or something to that effect.\n",
    "\n",
    "Google 'undefined behavior' in C.  It's not laziness.  I think it's actually an important part of what makes C fast.\n",
    "\n",
    "https://www.reddit.com/r/rust/comments/6g8v6p/seer_symbolic_execution_engine_for_rust/\n",
    "Forget the actual question, just read some of the comments.  This is the same thing as klee.  There’s even a comment about ‘super compilation’.\n",
    "\n",
    "Types are fundamental.  A class is a user defined type.  A type specifies the set of values of a variable, and the operations you can perform on it.  The user should know exactly what they can do with a piece of data at any time, and that means static typing.  Compile time errors are easier to catch than runtime errors.\n",
    "\n",
    "`Ok, just dump everything here.`\n",
    "\n",
    "The problem with current object oriented programming is currently being fixed.  Look at how oop used to be done (Java, C++), and how it’s done now (React, Node).  The problem was that every problem used to be an ‘is a’ problem rather than a ‘has a’ problem.  But is there a runtime cost to this?  Look at how Go does it.  But the heart of the problem is that you can’t say an object ‘is’ anything other than itself.  Yes, you can make a human class, and have any number of human objects spawn from that class.  But what if they have different jobs?  Then 1 human object would have a certain method, and another would not.  So maybe you have it implement some kind of interface.  But I feel like there’s definitely still a lot of room for further simplification.  It’s just that each individual object is unique, not just in its fields, but potentially in its methods as well.  It’s because true categorization, true generalization, is impossible.  All categorization, no matter how natural and intuitive it is, is arbitrary in the end, and there will be exceptions.  You had a fuzzy idea of being able to just refer to arbitrary methods in a class or struct.  I’m pretty sure this is a mixin.  Look at React, and why they think mixins are bad.  Also if you want to figure out what a mixin is, it’s not just a react thing, so just look up ‘wikipedia mixin’.  But then the react thing says something like ‘mixins were a bad idea because javascript is a dynamic language’.  A static language would catch all the crazy stuff at compile time and tell you about it.  Still, read the react thing.  It’s a very good description of the entanglement that results from mixins.  You might think to yourself ‘why not just put some thought into how you design it?’  That requires a lot of forethought.  These websites are simple products.  You know exactly what you want the website to do before you’ve written a single line of code.  The problem is how you design the code.  And if you make your code system easily changeable, you don’t need to put any thought into how you design it.  The design process isn’t something that should even need to be accounted for.  You should be able to code exactly what you want, and then easily change it later if you need to.\n",
    "\n",
    "Professor Aiken said in Static Vs Dynamic Typing Part 1 that ‘there are a lot of fancy new type systems that haven’t been implemented yet.’  What are they?  What exactly is he talking about?\n",
    "\n",
    "If everyone spoke English and used the English alphabet, would ascii be ok for everything?  Could we constrain chars to just 8 bits?\n",
    "\n",
    "Could you potentially use your language to mine crypto?  If it really use faster than C, and easier to code, then you should be able to do it more efficiently than other people.  Maybe something to consider later down the line, when you need money to sustain yourself.  Or potentially some other big data whatever.  Just find something that requires a lot of mindless number crunching.\n",
    "\n",
    "Wait, I understand why Python is locked to 1 processor:  it was originally designed for the Amoeba operating system.  Since Amoeba presents its multi-cpu system as a single unit, a program that explicitly asks to take up multiple cores doesn’t make sense.  Of course, the Amoeba operating system is dead, and python has been gimped ever since.  Good thing numpy and other libraries exist.\n",
    "\n",
    "Best commands for running a program:\n",
    "sweater <source file> \n",
    "This is reminiscent of python <source file>.  Will compile+run the program.\n",
    "Sweater compile <source file>\n",
    "./<binary file of same name>\n",
    "This will do the 2 steps separately.  This way you’re not re-compiling every time you run the program.\n",
    "\n",
    "Ok, maybe optional garbage collection would be nice.  You know, for certain projects.  I know you don’t plan to work on that kind of stuff, but if you’re trying to make a language that’s as fast as possible, leaving out something like that would be kind of sad.  I know you’re going for big data type stuff, but if you’re trying to make a really awesome compiler that can make really small fast binaries, maybe people would want to use it for embedded stuff, or maybe games.  Except for the fact that it uses garbage collection.  It just seems like a waste to have all of that functionality, and have this 1 barrier completely cut your language off from being usable in these 2 places.  What if you decide to pivot later?  Would it really be that hard?  Garbage collection is just an algorithm.  It shouldn’t be difficult to turn it on or off.  Also, it should be just that, on or off.  No halfway measures.  You either use the garbage collector, or you don’t.  Simpler, less bug prone, easier to optimize.\n",
    "\n",
    "Most optimization you can’t make guarantees about.  But you can guarantee stuff like ‘This uses the gpu’ or ‘this will automatically distribute tasks.’.  This is what sets your language apart.  \n",
    "\n",
    "69 LangZ.  It’s a language, it has a letter (Like C or R), and its for lazy people who don’t want to worry about parallelization, or making their code fast in general.\n",
    "\n",
    "70 asdf\n",
    "\n",
    "71 asdf\n",
    "\n",
    "72 What is IEEE?  Are there standards you need to comply with for ease of use?\n",
    "\n",
    "73 Check out the Go testing/benchmark library.  Interesting concept.\n",
    "\n",
    "74 Don’t forget DE Shaw Research is making that ‘specialized hardware’ to research drugs\n",
    "\n",
    "75 The reason matrices are so important is that they represent transformations on data.  They are 2 dimensional, mapping 1 type of data to another.  The user defines how they want data mapped.  That isn’t something a machine can just do automatically\n",
    "\n",
    "76 One problem (you’ve probably said this before) is that scientists code once, and run once.  Doesn’t matter how fast your program runs if it takes forever to compile.  How does lisp compile so fast?  Can you use parallelism to compile faster?\n",
    "\n",
    "77 Users should always be assured that their program is taking full advantage of all available hardware.  Should have a simple command or function that will tell the user what hardware the program can see.\n",
    "\n",
    "83 What makes bash scripting so “powerful?”  Probably how easy it is to manipulate input / output. \n",
    "\n",
    "84 Another point reiteration:  no project forks.  No options.  Every time a project forks, one of those tines will be used 99% of the time, the other 1% of the time.  Anyone working on the 1% is wasting their time.  That polly project is nice and all, but how many people are actually using it?  Perhaps there are a few people, but it would benefit a hell of a lot more people if it was incorporated into the normal Cpp compiler.  So why don’t they do that?  My uneducated guess is that integrating polly into the standard LLVM optimizer would require too many changes, too many compromises.  It would break too many things.  So the further along the LLVM compiler gets, the more difficult it will be to integrate polly.  So I certainly hope that what they’re working on is more than just applicable to C++.  But they’re at that ETH Zurich place.  Much smarter than you are.  They know what they’re doing.\n",
    "\n",
    "87 Wikipedia ‘array programming’ and ‘programming paradigms’.\n",
    "\n",
    "88 Could use attribute notation for certain operations like inverse / transpose.  A.i and A.t\n",
    "\n",
    "89 Why does every language use something like a pow function for exponentiation?  Python uses the ** operator.  Easy.\n",
    "\n",
    "90 Lets look at the ! operator.  If its in front of a variable, its logical NOT.  But if its at the end of a variable, you could make it a factorial.  If you use ‘and ‘ or ‘not’ then ! Could just be for factorial.  But why would you do this?  Because in math, factorial is a common enough operation that they gave it a special notation.  So it’s a common operation.  You want to optimize for common operations.\n",
    "\n",
    "91 Either Haskell or Erlang “let it crash”.  You’ll have to think about reliability.  Can you put this off, or does it need to happen now?  In general, what features are hard to implement later, and what can be put off?\n",
    "\n",
    "92 asdf\n",
    "\n",
    "93 Look at Prolog.  On wikipedia, it mentions something about using it to differentiate between compiler passes or something.   Also note the quick sort implementation.  Incredibly concise, even spared to something like python.\n",
    "\n",
    "94 asdf\n",
    "\n",
    "95 The Golang regex doc contains a link comparing Go’s implementation to Perl, Python, etc.  Worth looking at.\n",
    "\n",
    "96 The cathedral and the bazaar.  Also find some other work on the same subject.  Will teach about open source software development, the ups and downs, how to make it work, etc\n",
    "\n",
    "97 Databases will teach you about languages like SQL, something very different that what you’re used to.  Seems important to understand this paradigm that is so closely tied with big data.  Actually, it must be important, maybe even pivotal, to your language.  Less so than concepts like ‘cloud’, ‘distribution’, etc, but more so than most of the optimization stuff you’ve been thinking of.\n",
    "\n",
    "101 How can a compiler be built in such a way that it is ‘self-optimizing’?  Is this super-compilation?  Boot-strapping?\n",
    "\n",
    "102 Code can sit there optimizing for an arbitrary amount of time.  Maybe make it so that it just continually optimizes until you tell it to stop.  Is there some kind of discipline or methodology to this?  The setting for this idea is “computer, work on this problem until I tell you to stop at an arbitrary time”.  How can the computer work on the problem in such a way that whatever time it is told to stop, it can yield some result that is ‘beneficial’?  Something to do with streams of data?  Or just the idea of streams in general?  How can you make an algorithm that, when it is told to stop, will have to throw away a minimal amount of work?  Using the factorial thing again, lets say we told the computer “calculate factorial(100000000) until I tell you to stop”.  We’ll say the computer will never finish this.  If the computer used recursion and you stopped it at an arbitrary point, it would have nothing to show for all of its computation, since it didn’t save anything.  But if it used a dynamic programming implementation, it could at least say something like “I couldn’t get to 100000000, but I did manage to calculate all the factorials up to 40000”.\n",
    "\n",
    "104 There’s a lot for you to learn about runtime optimization.  If you make a program that takes in arbitrary data, you’ll need to make some runtime optimizations.  It can’t be done at compile time because you haven’t gotten the full picture yet.\n",
    "\n",
    "105 Syntactic sugar:  pretty, also restricting.  If it restricts what you can write, its a smaller domain space, and therefore easier to optimize.  Then again, users might get confused.  “This syntactically sugared expression should be identical to this unsugared expression, but for some reason it runs faster.  What gives?”  But maybe you’re conceptualizing it wrong.  If the sugared expression really is identical, then the compiler should see no difference, right?\n",
    "\n",
    "106 How do you make up for a bad design decision?  If you keep it, you have to put up with it forever.  If you change it, you break a lot of code.  What do?\n",
    "\n",
    "Lex and Flex, Bison and Yacc.  Which ones will restrict you (compare their licenses?).  Find out which ones documentation is better.  Also note that lex documentation applies to flex.  I think.  Mostly.\n",
    "\n",
    "107 Consider the latex mathematical format.  Could that be a form of ‘syntactical sugar’ that you could include in a language?\n",
    "\n",
    "108 Flex and Bison are basically just Cpp files with the single edition of a special syntax denoted by %’s at the beginning and end.  What if you made a language where you could just define your own mini-languages?  Is this somehow different from a macro?  Actually, could result in a lot of code completely incomprehensible to anyone else reading it.  Still, a fun and interesting concept.\n",
    "\n",
    "109 Why does constexpr exist in Cpp?  If we have a factorial function f(n), why do we need to say constexpr f(n) in order for Cpp to evaluate it at compile time?  If the compiler sees an f(5) somewhere in the program, it could easily just try to execute that function now.  If it works out, great, if it doesn’t, oh well, at least you’ve partially evaluated it.  I mean, there are certain implications.  Like what if the user wants to time the function.  Then it takes a long time to compile, and when they go to test the runtime it comes back as constant time.  That’s not exactly an accurate measurement.  Still, it seems like a really big waste to not do that automatically.  Perhaps another argument in favor of compilation + runtime together.\n",
    "\n",
    "110 An argument for making an optimizer backend for an already-existing language:  you get an enormous suite of test cases for free.  Just rip anyone’s code off GitHub, run it through your optimizer, and see if the overall behavior is the same.  Another option is to create a parser thing that turns language X into your language.  I mean, you compiled Python into C, so it should be possible.  But it seems like it would be difficult and bug-prone.  But it’s an interesting concept.  Language-agnostic test cases.\n",
    "\n",
    "111 Every dynamic programming algorithm has a recursive equivalent, right?  Does that mean you could auto-dynamize recursive functions?  Looking at the factorial function again, it seems like it would be really easy.\n",
    "\n",
    "112 Should find an in-browser equivalent of sublime and atom for ease of use with the cloud.\n",
    "\n",
    "The whole online-compilation thing.  There must be a way to save the work you do during compilation such that you won’t have to repeat it once you run it again.  Of course when you run a program it could output an optimized file, then on subsequent runs could check for the optimized file, but really that seems like it could get complicated and bug-prone very fast.  For instance, if a user timed multiple runs of their code, the first run would be much slower than the others.  Wait, never mind all of this.  By default, your code should not run with any optimizations.  If users want to test the speed of their algorithm, they should test it without applying any optimizations.\n",
    "\n",
    "You expect everyone using your language to use it on the cloud with a lot of processors.  All of that computing power shouldn’t just be taken advantage of at runtime.  You need to also seriously think about how you, the compiler writer, can take advantage of it at compile time.  How can you make optimizing faster, given all of these parallel cpu’s and gpu’s?  If you’re going to make a whole bunch of insane optimizations, that could end up being really slow.  Don’t let that happen.  One idea is pipelining the different stages of compilation.  One thread is lexing a part of the program, and it passes what it lexes to the parsing thread not as one large chunk, but as a stream.  I’m almost certain they already do this.  Right?  But it must take on a little more nuance in a many-core computational environment.  Ok, yeah, you are dumb.  If you have 4 cores, and 5 files to compile, then your first task is to lex 4 files.  Then whichever one gets done lexes the next file.  Pipelining is only useful if you have cores that aren’t being used.  So I guess it would be faster for single file scripts.  But by their very nature they already compile fast.  Wait, but if you’re working on a giant parallel cluster, maybe you do have more cores than you have files.  So maybe pipelining would be useful.\n",
    "\n",
    "Here’s an idea for your language:  crowdsource super-compilation.  When a user isn’t actually running anything on their cloud, (or maybe while they’re running things on their cloud), you could ask them if they could run a script that would search through the compiler source code using 3SAT, looking for optimizations.  Then any optimizations found would be sent back to you.  A super easy way for users to contribute to the project without actually having to put in any work.\n",
    "\n",
    "TCP vs Unix sockets.  Makes me think that learning 168 might be more useful than previously thought.  Answers the question “How do (or should) nodes in a cluster communicate?”\n",
    "\n",
    "A problem with separate compilation:  Let’s say your scientist has a big data problem.  If they ran a script in python, it would take a week of number crunching.  With your new language, it would take 2 hours of compilation, and 4 hours of number crunching.  That sounds way better, but then your scientist has to sit there for 2 hours doing nothing, waiting for the program to compile, before they hit run and head home.  You’re trying to let the scientist have more free time than if they were using python, but in this scenario they actually have less free time.  So perhaps that’s a point in favor of non-separate compilation.  Of course, the scientist could just type a command like “cool_compiler my_script.cl -o my_script && ./my_script”, but that’s complicated.  Hm… maybe a simple solution is to just have a command that’s something like “build+run” or something like that.  Then again, compiling takes like 0 time unless you have a really really big project, and code-wise, scientific computing doesn’t use large codebases, right?\n",
    "\n",
    "Feature\n",
    "Don’t actually include this, as it’s kind of related to your thought about generative compilers.  You know how regex can only count ‘modulo’ some number?  If you want to count nested parens, couldn’t you have some expression like “#parens % 2 == 0 | #parens % 3 == 0 | #parens % 5 == 0 | ….”  This way, your regex can count all sets of parens so long as the total nesting isn’t some product of primes that you haven’t taken into account.  So just make the number of prime mods significantly large.\n",
    "\n",
    "Feature\n",
    "This isn’t really a feature, but you should have lots of examples in your documentation that do a ‘using namespace math’ so you can show how concise math operations can be.  Look at how latex formats everything.  You could make it similar to that, possibly.\n",
    "\n",
    "Feature\n",
    "Whitespace is good not just because it’s cleaner, but because it frees up other punctuation.  Think about all the different punctuation, and how it’s wasted.  #, $, {}, etc.  Why do we use # in front of an include?  What is the point.  # and the others should be reserved for operations.  An operation is something you use all the time.  We don’t have to have to add two numbers together by doing add(x, y), right?  As often as possible, we want to use operators, which are much cleaner.  Things like definitions shouldn’t have their own special single characters.  Funcs should be declared by saying ‘func’, macros should be declared by saying ‘macro’, etc.  Then again, you can essentially create infinite operators just by repeating 1 of these symbols.  You could make it more compact by mixing up the symbols.  You’re using ** for taking powers of stuff.  You could use $, $$, $$$, etc, and each would mean a different thing and be easy to lex.  You could also take $%, $%#, etc.  Maybe you should make it easy for users to construct their own operators.  Well, it probably already is easy for them to construct their own operators, but just encourage it or something.\n",
    "\n",
    "Goal\n",
    "A lot of these features are about usability.  Can be summed up like so:  a user wonders ‘what library should I use?’  They should 99% of the time be able to just grab a library that has your stamp of approval.\n",
    "\n",
    "Feature\n",
    "There should be a config file for each project, like a gitignore.  These features should be things like spacing.  Things that don’t matter to the compiler but matter to the user.\n",
    "\n",
    "Feature\n",
    "‘Go get’ is just a fancy git clone.  Remember that comic?  But also interesting.  An easy way to download stuff.  But it also gives users 2 options.  Hm….  Then again, you could make it just for ‘extended’ libraries that you write yourself.\n",
    "\n",
    "Feature\n",
    "Should be able to compile and get a single binary without having to do any Makefile stuff.  Why do big projects always have some crazy makefile?\n",
    "\n",
    "Resource\n",
    "Julia supposedly has ‘powerful shell like abilities to manage other processes’.  You were talking about the conciseness of shell scripts.  This sounds interesting.  Another thing is that Julia isn’t ‘separately compiled’.  Wtf.  It takes literally 1 command to compile stuff.  Maybe its just-in-time compiled.\n",
    "\n",
    "Goal\n",
    "Distributed systems currently needs some library like OpenMPI to understand that there are other systems connected.  Need to figure out a way to put this on the back end so that the user doesn’t need to worry about it.\n",
    "\n",
    "Goal, Blob\n",
    "About cloud computing and why its a huge factor.  The cloud has virtualization of hardware.  It also had highly homogenoeus hardware, meaning you need to build for much fewer targets.  Also means easier access to hardware since since we have virtualization to abstract it.\n",
    "\n",
    "Goal, Blob\n",
    "Another possible principle.  Maybe there’s no single best way to accomplish every task, but there should be one obvious way.  I think this is like python.  There should be minimal libraries.  If you have an idea to make the language better, it should make the language better in all cases, which means its a decision the coder shouldn’t have to make, which means it should be written directly into the compiler.\n",
    "\n",
    "Standards\n",
    "Something else that must be looked into, but much later, is how will the licensing work?  Rememberr that gcc has a license that caused apple to switch to Clang, which had a less restrictive license.\n",
    "\n",
    "Goal\n",
    "Use specialized hardware as much as possible.\n",
    "\n",
    "Blob\n",
    "Remember what you said about the cloud and how hardware would become more and more specialized?  This is another big one to consider.  How can you optimize as efficiently and painlessly as possible for hardware that hasn’t come out yet?  Is the concept of FPGA’s related to this at all?\n",
    "\n",
    "Goal Blob\n",
    "Another strong consideration is ‘environment’.  Is it barebones like C/Go, or is it very contained, like java, or python, which even has its own installer for everything, pip.  \n",
    "\n",
    "Resource\n",
    "One component of the success of python is that the creator, Guido Van Possum, is the ‘benevolent dictator for life’.  I would assume this meant he had the last say on all design decisions.  This is counter intuitive.  If different people have different preferences, how did one guys decisions lead to such unanimous satisfaction with the language?  \n",
    "\n",
    "Goal\n",
    "If you ever forget why you’re doing this, remember that Jay let his comp run overnight to get pictures of fly neurons.\n",
    "\n",
    "Blob\n",
    "Remember that malloc sucks, and it isn’t something that the coder should have to think about, but is necessary for the sake of performance.  Don’t call it malloc.  Try to make it as intuitive as possible.  Malloc could be ‘save’ and free could be ‘trash’.  Give pointers the same treatment.  Forget convention.  This isn’t for computer scientists, it’s for scientists.  Just have to tell the scientists ‘at the end of your function, everything gets trashed unless you explicitly save it’.  \n",
    "\n",
    "Resource\n",
    "If you need an example problem to use, consider your CS170 project.  You know that project inside out, and you know its really computationally intensive.  If that doesn’t work, consider a generic CS170 project.  Maybe ask a professor.\n",
    "\n",
    "Goal\n",
    "\n",
    "\n",
    "Goal\n",
    "Your language maximizes runtime with the constraint of being syntactically as simple as Python.  Your language does not maximize simplicity with the constraint of being faster than C.\n",
    "\n",
    "Feature\n",
    "Its not part of syntax, but you also don’t want a bunch of library calls like you would have to make in C to parallelize.  Nor do you want a bunch of conflicting compiler options.  All you want is 1 cohesive compiler option.  The MacOS of compilers.\n",
    "\n",
    "`What are some more concrete concepts you need to consider?`\n",
    "\n",
    "SQL and all its implementations.  How will these be used in conjunction with your language?\n",
    "\n",
    "Hacker News article about thread 'nurseries'.\n",
    "\n",
    "Type inference.\n",
    "\n",
    "Read “Go’s Declarative Syntax”. Has a good explanation of why C pointers are how they are, and why Go is different.  Maybe instead of ‘pointers’ you could call them ‘boxes’, since you ‘open’ them to get the actual data.  Or maybe that’s too close to packages.  Maybe ‘portal’ is a better word?  But if you’re a scientist, do you even need pointers?  Actually, you know the MapReduce model takes in functions as arguments.  So scientists need functions as args.  I think that counts as needing pointers.\n",
    "\n",
    "garbage collection and its alternatives.  Specifically, I think you should go for optional garbage collection.  This way, you can write libraries and manually collect garbage while also letting your users have garbage collected automatically.\n",
    "\n",
    "Containerization.\n",
    "\n",
    "Machine learning.  It's a bag of tricks.  Rather than trying to figure out which tricks are the best, just try all the tricks and see which ones give the best results.\n",
    "\n",
    "Data pipelines.  How do users scrub data, put it into a recognizable format, feed it into a program?\n",
    "\n",
    "IEEE, Posix, and potentially other standards you will have to comply with.\n",
    "\n",
    "Licensing, such as GPL vs BSD.\n",
    "\n",
    "Explicit documentation.  Document everything.  If it's not documented, it doesn't exist.  Users will get frustrated and quit.  Look at the java docs.  Those are good.  Remember at Scale there were 2 documents:  the README, and the wiki.  Nobody ever wanted to change the README because you had to go through bureaucracy to change it.  It had to be spotless before it could be added.  It was much easier to change the wiki.  You need to make documentation easy to change.  You should want to update it.  Maybe you could have some webpages that are 'set in stone' and some that are less so.  Then let users know that there's a difference.  Maybe that sounds like a 'this is right' and 'this is wrong'.  Hm...how do you make people understand the difference?\n",
    "\n",
    "Golang seems to be of particular interest these days.  A new language that is actually popular and compiled.  If you google 'most popular programming languages on github', Go is on there.  It's pretty low, but it beat out C, Swift, and Scala.  Only ones it didn't beat out were the big hitters.  Javascript, Python, Java, C++, etc.  Python is number 2 by the way.  I wonder how it did that?  If you look at 'the zen of python' I think the most important one is 'There should be one—and preferably only one—obvious way to do it.'  That is why everyone loves python.\n",
    "\n",
    "https://jguegant.github.io/blogs/tech/meta-crush-saga.html\n",
    "This guy Jguegant made a ‘compile time game’.  He says ‘most of the computations are done during the compiler phase.'  Interesting.  How does this work?  Supposedly it’s very computationally efficient.  But also your compiler is running over and over again.  How could that possibly be efficient? \n",
    "\n",
    "Gofmt is an interesting simple tool.  Makes me think about how tools aren’t really a standard thing.  There isn’t just a compiler, and a makefile, or an interpreter.  There isn’t just a java environment or whatever.  It’s whatever you want it to be.  I feel like tools can definitely be simpler, more helpful.  Remember that lisp debugger thing that let you rewind code?  That was pretty interesting.  Why don’t other languages do that?\n",
    "\n",
    "That start up ‘Big Stream’ was doing a whole bunch of big data compiler stuff.\n",
    "\n",
    "Rust seems interesting.  Was voted ‘most loved programming language’ on stack overflow in 2016, 2017, and 2018.  Also has an interesting not-garbage-collector thing.  I think I’ve mentioned this before, but Bigstream was modifying compilers to make them better for big data or something.\n",
    "\n",
    "There's so many kinds of parallelization. SIMD and MIMD and bit level and instruction level and task level.  Multi-core and symmetric and distributed.  So so many different techniques that no one uses because it takes too long to implement.\n",
    "\n",
    "Why do we need virtual addressing?  Why can't the compiler use the physical addresses?  Wouldn't that be faster?  There's probably something you're missing here.\n",
    "\n",
    "Something on parallelism:  If we have a task that we can make parallel, the best way to do it is to parallelize at the ‘highest’ possible level that we can.  Lets say we have a big list of matrices.  Each line in our list is a row of matrices.  Lets say each row is 100 matrices, and there are 10000 rows.  You want to multiply all 100 matrices together for each row, so your task is to spit out a list of 10000 matrices.  We’ll also say you have 4 cores to do this with.  You could split it up in a number of ways.  You could have each core multiply 25 matrices together for each row, then do 4 more multiplications to get the final product.  This involves 3 splits for each row, so 30000 splits, and 3 merges for each row, so 30000 merges.  Or you could just split the rows into 4 chunks and have each core work on 2500 rows.  This is just 3 splits, and 3 merges.  Much better.  So when jobs >> workers, splitting up your workload at the highest level possible is probably the best idea.  But what about if we have the same number of workers as jobs, or workers >> jobs?  The current ‘fastest’ supercomputer in the world is Taihu Light, which has 10,649,600 total cores, or workers.  Then how would you split up the work?\n",
    "\n",
    "Another separate thought on parallel processing:  splitting up tasks takes time, any you want all of your parallel processes to finish at the same time, so maybe you should give your earlier processes a little more work, since they start earlier.  Would that make much of a difference?  Is that part of load balancing?\n",
    "\n",
    "If polly makes C++ perform 100x better on big data sets, how come we’re not hearing about it?  How come libraries like numpy aren’t suddenly 100x faster?  Isn’t Python compiled into C++?  Maybe it’s a separate project because it’s so hard to merge with the regular optimizations present in the normal optimizer.  What if you made a compiler thing that only worked on TPU’s?  Since this thing works on CPU’s, perhaps its optimizations clash with the more classical optimizations?\n",
    "\n",
    "You want ‘automatic’ parallelization.  What is automatic parallelization?  If I use numpy, is that ‘automatic’?  Why is numpy a library and not a built in thing?  I think ‘automatic’ parallelization means it’s parallelized without you having to use any libraries or fancy classes.  Just primitives.  Maybe classes too.  But still not sure.  The program must be written in a completely sequential manner.  Then the compiler automatically makes it parallel.  What does it mean for the program to be ‘sequential’?  Are matrices a special exception?  They are a concept that allows us to ‘parallelize’ something in our mind.  While it is explicit parallelization, it is simpler for us to conceptualize it in the form of a matrix than 1 by 1.  So matrices should be allowed to be in your code.  Things like writing pragma omp parallel or calling go func are definitely explicit parallelism that you shouldn’t need.  So you should compare based only on being able to use matrices, and perhaps setting compiler options.  If the user has to think 'i'm going to do it this way because I know the compiler will parallelize it', then you're doing your language wrong.  They shouldn't have to think about that.\n",
    "\n",
    "Matrices are a fundamental part of data.  One dimension to specify all aspects of a single object, another dimension to specify all objects.  If those objects can come together to form the ‘aspects’ of an even bigger object, you don’t need another dimension, you just need a matrix transformation.  Matrices and matrix operations should be defined in a primitive way, not through classes.\n",
    "\n",
    "Why when you have a compiled language, the options for changing certain behaviors are always hidden behind some menu or as a compilation tag or switch.  Switches for turning on/off garbage collection, or static type checking, or automatic formatting, or whatever environment variables.  Why not just put them in your main file?  Have a file called start/main where all your configurations go.  Now you don't need to remember any terminal commands or a ton of different files.  It's all right there, in the most obvious place.  You might think 'noooo I don't want to copy and paste my config every time I make a new project.'  Well, you don't have to.  The compiler should be able to function in the normal way, or in this much easier way as well.  Now you don't need to know what a bash_rc vs a bash_profile is (which by the way are different on MacOS vs Linux).\n",
    "\n",
    "When doing machine learning, why are we the ones separating pictures into learn and test sets?   I feel like it would be easier if you just give the program all the pictures and labels, then the machine decides what goes into the learning and testing sets.  The idea would be that you want the highest possible accuracy with the smallest possible learning set.  This seems like it would take exponentially more time, though.  But you want your algorithm to learn the ‘essence’ of whatever you give it.  The smaller the learning set, the more you have condensed the essence of the thing it’s trying to learn.  This might be wrong, but right now I think machine learning algorithms just divide the pictures randomly.  I don't think choosing randomly is a good idea.  There's obviously some arrangement of pictures into training / test sets that would result in the optimal way to do things in the wild.  Oh, here's an application of making your training sets smaller: you can retrain much faster.  It would be a way to filter out the useless / bad data.\n",
    "\n",
    "Notes from PhD Grind———————————————————————————\n",
    "Page ??? (The entirety of year 1):  What you might end up like if you pursue a Ph.D\n",
    "\n",
    "Page 22:  Send cold emails.\n",
    "\n",
    "Whats the problem?\n",
    "What’s my proposed solution?\n",
    "What compelling experiments can I run to demonstrate the effectiveness of my solution?\n",
    "\n",
    "Page 23:\n",
    "\n",
    "Professors are motivated by having their names appear on published papers, and computer science conference papers usually need strong experiments to get accepted for publication. Thus, it’s crucial to think about experiment design at project inception time.\n",
    "\n",
    "Page 30:\n",
    "\n",
    "I cannot re-emphasize this point enough times: Properly calibrating your pitch to the academic sub-community you’re targeting is crucial for getting a paper accepted.\n",
    "\n",
    "Page 35-36:\n",
    "\n",
    "Make sure you and your advisor actually have similar goals in mind.\n",
    "\n",
    "Page 37-38:\n",
    "\n",
    "The horror.  Years and years for no results.  Also, remember that this is Stanford.  The place you want to go.  Also note that he’s making ‘incremental’ improvements to the already existing Klee stuff.  That’s basically what you want to do.  Just assemble a whole bunch of stuff that already exists.  You’re not really doing ground-breaking work, just implementing other people’s work.  Potentially with modifications, but still.  You can’t make a paper out of this.  Well, maybe you could, but it would be difficult.  And you would be on a timer.  And you would have to capitulate to the professor.  Ugh.  There’s no time for that.  You don’t need to publish a paper, you need to publish a language.  But wasn’t Julia someone’s research project?  Hm… doesn’t seem like it.  But you want control.  You need to be able to make all of the decisions, right now.  What you want to make is a product.  It’s not truly an exploration of new ideas, it’s a synthesis of ideas into something real.  And do those people go to grad school?  No, they just make it.  You can’t be wasting your time with some feet-on-desk professors half-assed ideas.\n",
    "\n",
    "Page 43:\n",
    "Marketing buzzwords.  Required to publish papers.\n",
    "\n",
    "Page 47:\n",
    "Online submission forms are black holes. Anything is better than blindly submitting online.\n",
    "\n",
    "53:  Search the web for related work.  Very important.\n",
    "\n",
    "58:  It turns out that ignoring your instructors and doing whatever you want is what makes you the most productive.  As you already knew.  “Those three years—my latter half of grad school—were the most creative and productive of my life thus far, in stark contrast to my meandering first half of grad school”\n",
    "\n",
    "63:  If you are a computer science researcher, your work will never be directly used in practice.  You simply don’t have the time to get things up to the production-level standards required for people to actually want to use your thing.  “To convince someone to try IncPy, I would need to guarantee that it works better than regular Python in all possible scenarios.”  Well, that’s your language, right?  All you have to do is put colons in front of all of your variable assignments, then instead of doing python <myfile>, you do sanic <myfile>.  Of course, gross oversimplification, but still.\n",
    "\n",
    "65:  Dependency conflicts are annoying.  The more integrated your stuff is with code that already exists, the more screwed you are.  What kinds of things will you have to depend on?\n",
    "\n",
    "69:  Your scholarships are on a timeline so you’re on your own if you don’t publish a bunch of papers right away.  So they make you waste your time with useless classes and bad research, then tell you that you can’t graduate unless you shit out a bunch of papers.\n",
    "\n",
    "70:  This incPy thing turned out to be one of the components of a jupyter notebook, in a way.  You run some code, you see the output, you can refer to that same code later.  This makes me think that your language needs something like that.  That might be difficult considering your language is compiled.  Or would it be difficult?  It looks like jupyter works with Go, so it shouldn’t be too bad.\n",
    "\n",
    "73:  Jupyter isn’t just really convenient, in a lot of ways it’s essential.  You need to be able to reproduce your research, not just present it.  How can you run programs really really fast when you’re in a Jupyter notebook?\n",
    "\n",
    "74:  ‘Why not make it a general application?’  Because the larger your audience is, the less you will be able to deliver to them.\n",
    "\n",
    "74-75:  ‘Why hadn’t anyone thought of this yet?’  He says he googles it and doesn’t get much back, but this seems like Containers to me.  It’s just containers.  \n",
    "\n",
    "76:  “I’ll always miss those purer times. In my current job, there’s no way I can block off three weeks just to code non-stop!”  HMMMMMM….  Maybe get a different job?  Well, he’s probably happy where he is, but you wouldn’t be.\n",
    "77:  “This is a very important point. It’s not our job as academics to ship polished products; that’s the role of companies.”  You want to ship a polished product.\n",
    "\n",
    "80-81:  He got an offer to just work on his open source project at Google.  Just get paid money to do what he had been previously doing.\n",
    "\n",
    "87:  This isn’t the first place this is mentioned, but “And without motivated students to grind through the tough manual labor, it’s impossible to get respectable publications.”  Your thing will consist of a lot of tough manual labor.  \n",
    "\n",
    "88:  Creative freedom is not to be found anywhere.  Freedom to simply work on what interests you is also not to be found anywhere.\n",
    "\n",
    "90:  Living arrangement matters for your productivity.\n",
    "\n",
    "92-93:  An example of the constant state you want to achieve.  Also note that this guy made that one environment diagram program that is useful.  Getting used to new things is a difficult, frustrating process.  You have to push through that to get to the good part.  Of particular importance:  “After years of grinding on uncertain and failed projects earlier in grad school, I now felt invigorated working intensely towards a target that I knew I could feasibly achieve.”  You’re motivated by this compiler thing because it seems so obvious, so simply achievable to you.  Maybe not an easy task, but definitely a task that is possible.\n",
    "\n",
    "100:  Produce results.  Not just for other, but for yourself, in order to stay motivated.  Also read the rest of the lessons, they seem very insightful.  Especially point 20.  Sad to say that effort alone isn’t enough.  You need to apply the right kind of effort.\n",
    "\n",
    "Last Page:  He says that it was fulfilling, etc, etc.  But he makes a compelling argument for you not to pursue a graduate degree.  Working towards a graduate degree will force you to work hard.  Do you need someone to force you to work hard?  No.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
